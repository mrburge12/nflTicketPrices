theme_bw() +
facet_wrap(~variable, ncol=3,scale="free")
#Generate a Monte Carlo Sample
generateMCSample<-function(n, vals){
require(randtoolbox)
require(plyr)
require(reshape2)
#Generate a Sobol sequence
sob<- sobol(n,length(vals))
#Fill a matrix with the values inverted from unifrom values to distributions of choice
samp <- matrix(rep(0,n*(length(vals)+1)), nrow=n)
samp[,1] <- 1:n
for (i in 1:length(vals)) {
l <- vals[[i]]
dist <- l$dist
params <- l$params
samp[,i+1] <- eval(call(paste("q",dist,sep=""),sob[,i],params[1],params[2]))
}
# Convert matrix to data frame and label
samp <- as.data.frame(samp)
names(samp) <- c("n",laply(vals, function(l) l$var))
return(samp)
}
n<-1000 #number of simulations to run
#List described the distribtuion of each variable
vals <- list(list(var="Uniform",
dist="unif",
params=c(0,1)),
list(var="Normal",
dist="norm",
params=c(0,1)),
list(var="Weibull",
dist="weibull",
params=c(2,1)))
#Generate the smaple
samp<-generateMCSample(n,vals)
#Plot with ggplot2
library(ggplot2)
samp.mt <- melt(samp,id="n")
gg <- ggplot(samp.mt,aes(x=value)) +
geom_histogram(binwidth=0.1) +
theme_bw() +
facet_wrap(~variable, ncol=3,scale="free")
#Generate a Monte Carlo Sample
generateMCSample<-function(n, vals){
require(randtoolbox)
require(plyr)
require(reshape2)
#Generate a Sobol sequence
sob<- sobol(n,length(vals))
#Fill a matrix with the values inverted from unifrom values to distributions of choice
samp <- matrix(rep(0,n*(length(vals)+1)), nrow=n)
samp[,1] <- 1:n
for (i in 1:length(vals)) {
l <- vals[[i]]
dist <- l$dist
params <- l$params
samp[,i+1] <- eval(call(paste("q",dist,sep=""),sob[,i],params[1],params[2]))
}
# Convert matrix to data frame and label
samp <- as.data.frame(samp)
names(samp) <- c("n",laply(vals, function(l) l$var))
return(samp)
}
n<-1000 #number of simulations to run
#List described the distribtuion of each variable
vals <- list(list(var="Uniform",
dist="unif",
params=c(0,1)),
list(var="Normal",
dist="norm",
params=c(0,1)),
list(var="Weibull",
dist="weibull",
params=c(2,1)))
#Generate the smaple
samp<-generateMCSample(n,vals)
#Plot with ggplot2
library(ggplot2)
samp.mt <- melt(samp,id="n")
gg <- ggplot(samp.mt,aes(x=value)) +
geom_histogram(binwidth=0.1) +
theme_bw() +
facet_wrap(~variable, ncol=3,scale="free")
gg
install.packages("forecast")
install.packages("tseries")
install.packages("ggplot2")
library('ggplot2')
library('forecast')
library('tseries')
daily_data = read.csv('day.csv', header=TRUE, stringsAsFactors=FALSE)
cd
pwd
library('ggplot2')
library('forecast')
library('tseries')
daily_data = read.csv('day.csv', header=TRUE, stringsAsFactors=FALSE)
library('ggplot2')
library('forecast')
library('tseries')
dataPath<-'Desktop'
daily_data = read.csv('dataPath/day.csv', header=TRUE, stringsAsFactors=FALSE)
library('ggplot2')
library('forecast')
library('tseries')
dataPath<-'Desktop'
daily_data = read.csv(dataPath/'day.csv', header=TRUE, stringsAsFactors=FALSE)
library('ggplot2')
library('forecast')
library('tseries')
daily_data = read.csv('day.csv', header=TRUE, stringsAsFactors=FALSE)
library('ggplot2')
library('forecast')
library('tseries')
daily_data = read.csv('C:/Users/g1mxb12/Desktop/Random/day.csv', header=TRUE, stringsAsFactors=FALSE)
daily_data$Date = as.Date(daily_data$dteday)
View(daily_data)
View(daily_data)
ggplot(daily_data,aes(Date,cnt))+geom_line()+scale_x_date('month')+ylab("Daily Bike Checkouts")+xlab("")
count_ts = ts(daily_data,[,c('cnt')])
daily_data$clean_cnt = tsclean(count_ts)
ggplot()+geom_line(data=daily_data,aes(x=Date,y=clean_cnt))
count_ts = ts(daily_data[, c('cnt')])
daily_data$clean_cnt = tsclean(count_ts)
ggplot()+geom_line(data=daily_data,aes(x=Date,y=clean_cnt))
daily_data$cnt_ma = ma(daily_data$clean_cnt, order = 7)
daily_data$cnt_ma30 = ma(daily_data$clean_cnt, order = 30)
ggplot()+geom_line(data = daily_data, aes(x = Data, y = clean_cnt, colour = "Counts"))+
geom_line(data = daily_data, aes(x = Date, y = cnt_ma, colour = "Weekly Moving Average"))+
geom_line(data = daily_data, aes(x = Date, y = cnt_ma30, colour = "Monthly Moving Average"))+
ylab('Bicycle Count')
ggplot()+geom_line(data = daily_data, aes(x = Date, y = clean_cnt, colour = "Counts"))+
geom_line(data = daily_data, aes(x = Date, y = cnt_ma, colour = "Weekly Moving Average"))+
geom_line(data = daily_data, aes(x = Date, y = cnt_ma30, colour = "Monthly Moving Average"))+
ylab('Bicycle Count')
count_ma = ts(na.omit(daily_data$cnt_ma), frequency=30)
decomp = stl(count_ma, s.window="periodic")
deseasonal_cnt <- seasadj(decomp)
plot(decomp)
adf.test(count_ma, alternative = "stationary")
count_ma = ts(na.omit(daily_data$cnt_ma), frequency=30)
decomp = stl(count_ma, s.window="periodic")
deseasonal_cnt <- seasadj(decomp)
plot(decomp)
adf.test(count_ma, alternative = "stationary")
Acf(count_ma, main='')
Pacf(count_ma, main='')
Acf(count_ma, main='')
Pacf(count_ma, main='')
count_d1 = diff(deseasonal_cnt, differences = 1)
plot(count_d1)
adf.test(count_d1, alternative = "stationary")
Acf(count_d1, main='ACF for Differenced Series')
Pacf(count_d1, main='PACF for Differenced Series')
ata
dataPath<-'C:/Users/g1mxb12/Dropbox (Research)/SignalingEffectsFWG/Data/Reduced_Form_Models'
data<-readxl('allVariables_Greenbook_BlueChip_BothFreq.xlsx')
install.packages("readxl")
data<-readxl('allVariables_Greenbook_BlueChip_BothFreq.xlsx')
data<-readxl_example('allVariables_Greenbook_BlueChip_BothFreq.xlsx')
data<-readxl_example("allVariables_Greenbook_BlueChip_BothFreq.xlsx")
data<-read_excel("allVariables_Greenbook_BlueChip_BothFreq.xlsx")
install.packages("xlsx")
data<-read.xlsx("allVariables_Greenbook_BlueChip_BothFreq.xlsx")
data<-read.xlsx2("dataPath/allVariables_Greenbook_BlueChip_BothFreq.xlsx")
data<-read.xlsx("dataPath/allVariables_Greenbook_BlueChip_BothFreq.xlsx")
data<-readxl::("dataPath/allVariables_Greenbook_BlueChip_BothFreq.xlsx")
data<-readxl("dataPath/allVariables_Greenbook_BlueChip_BothFreq.xlsx")
data<-read.table("dataPath/allVariables_Greenbook_BlueChip_BothFreq.xlsx")
cd
pwd
wd
wd()
#Read in the data
dataPath<-'C:/Users/g1mxb12/Dropbox (Research)/SignalingEffectsFWG/Data/Reduced_Form_Models'
install.packages("readxl")
library(readxl)
data<-read_excel("dataPath/allVariables_Greenbook_BlueChip_BothFreq.xlsx")
#Install package for VARs
data<-read_excel("dataPath/allVariables_Greenbook_BlueChip_BothFreq.xlsx")
library(readxl)
allVariables_Greenbook_BlueChip_BothFreq <- read_excel("C:/Users/g1mxb12/Dropbox (Research)/SignalingEffectsFWG/Data/Reduced_Form_Models/allVariables_Greenbook_BlueChip_BothFreq.xlsx")
View(allVariables_Greenbook_BlueChip_BothFreq)
install.packages("vars")
library("crayon", lib.loc="~/R/win-library/3.4")
x<-1
help crayon
? crayon
install.packages(c("httr", "jsonlite", "lubridate"))
library(httr)
library(jsonlite)
library(lubridate)
url  <- "https://api.seatgeek.com/2/events?q=nfl+football&client_id=6a9738d0c19f46825345dc5f47527b906a42c176a643b86adca2fd2ecbea65ad&client_secret=MTI0MTQ5NzR8MTUzMjYxOTczNC4wMw"
result <- GET(url = url)
View(result)
install.packages(c("httr", "jsonlite", "lubridate"))
library(httr)
library(jsonlite)
library(lubridate)
url  <- "https://api.seatgeek.com/2/events?&q=nfl+football&client_id=6a9738d0c19f46825345dc5f47527b906a42c176a643b86adca2fd2ecbea65ad&client_secret=MTI0MTQ5NzR8MTUzMjYxOTczNC4wMw"
result <- GET(url = url)
install.packages(c("httr", "jsonlite", "lubridate"))
View(result)
install.packages(c("httr", "jsonlite", "lubridate"))
library(httr)
library(jsonlite)
library(lubridate)
url  <- "curl https://api.seatgeek.com/2/events?q=nfl+football&client_id=6a9738d0c19f46825345dc5f47527b906a42c176a643b86adca2fd2ecbea65ad&client_secret=MTI0MTQ5NzR8MTUzMjYxOTczNC4wMw"
result <- GET(url = url)
? curl
install.packages(c("httr", "jsonlite", "lubridate"))
library(httr)
library(jsonlite)
library(lubridate)
url  <- curl(url="https://api.seatgeek.com/2/events?q=nfl+football&client_id=6a9738d0c19f46825345dc5f47527b906a42c176a643b86adca2fd2ecbea65ad&client_secret=MTI0MTQ5NzR8MTUzMjYxOTczNC4wMw")
result <- GET(url = url)
install.packages(c("httr", "jsonlite", "lubridate"))
?rnorm
?skew
??skew
?rnorm
x<- rnorm(5,0,1)
y<-rnorm(5,0,2)
z<-rnorm(5,0,3)
View(x)
x
y
z
m<-rnorm(5,0,1)
m
?median
median(x)
median(y)
median(z)
n<-rnorm(5,0,4)
o<-rnorm(5,0,10)
m
n
o
median(m)
median(n)
median(o)
#install.packages(c("tidyverse", "stringr", "knitr", "curl", "jsonlite", "XML", "httr", "rvest", "ggmap"))
library(tidyverse)
library(stringr)
library(knitr)
library(curl)
library(jsonlite)
library(XML)
library(httr)
library(rvest)
library(ggmap)
###################
## Pull Event Data
###################
apiKey<-"BDMDMNv2wXwAZMRAlavHs371eUadxLbq"
consumerSecret<-"o8eJaby9afZL45s3"
keyword<-"NFL"
segmentID<-"KZFzniwnSyZfZ7v7nE"
sementName<-"Sports"
genreID<-"KnvZfZ7vAdE"
genreName<-"Football"
subgenreID<-"KZazBEonSMnZfZ7vFE1"
subgenreName<-"NFL"
typeID<-"KZAyXgnZfZ7v7l1"
typeName<-"Group"
subtypeID<-"KZFzBErXgnZfZ7vA7d"
subtypeName<-"Team"
size<-200
# Function for API Query
ticketMasterLink <- function(apiKey, keyword, size){
rootURL<-"https://app.ticketmaster.com/discovery/v2/events.json?"
params<-c( "apikey=", "keyword=","size=")
values<- c(apiKey, keyword, size)
args<- str_c(params, values, collapse = "&")
str_c(rootURL, args)
}
# requestNFLGames
nflGames<-ticketMasterLink(apiKey,keyword,size)
con<-curl(nflGames)
answer_json<-readLines(con)
response<-
answer_json %>%
prettify() %>%
fromJSON()
eventData<-response$`_embedded`$events
eventData<-eventData[!(eventData$dates$status$code %in% c("offsale")), ]
eventData<-eventData[(eventData$promoter$id %in% c("705")), ]
#############################
## Pull Inventory Status Data
#############################
inventoryInfo <- vector("numeric", nrow(eventData))
inventory<- vector("numeric", nrow(eventData))
answer_json<- vector("numeric", nrow(eventData))
for (i in 1:nrow(eventData)) {
inventoryStatusLink <- function(apiKey, eventID){
eventID <- eventData[i,3]
rootURL<-"https://app.ticketmaster.com/inventory-status/v1/availability?"
params<-c("events=", "apikey=")
values<- c(eventID, apiKey)
args<- str_c(params, values, collapse = "&")
str_c(rootURL, args)
}
inventoryInfo[i]<-inventoryStatusLink(apiKey,eventID)
con<-curl(inventoryInfo[i])
answer_json[i]<-readLines(con)
inventory[i]<-
answer_json[i] %>%
prettify() %>%
fromJSON()
}
x <- "{}" #or whatever
inventoryStatus<-str_replace_all(answer_json, "{[[:punct:]]}", "")
inventoryStatus<-str_replace_all(inventoryStatus, "eventId","")
inventoryStatus<-str_replace_all(inventoryStatus, "status","")
inventoryStatus<-str_replace_all(inventoryStatus,"FEWTICKETSLEFT", "")
inventoryStatus<-str_replace_all(inventoryStatus,"TICKETSAVAILABLE", "")
inventoryStatus<-inventoryStatus[!grepl("TICKETSNOTAVAILABLE", inventoryStatus)]
#inventoryStatus<-as.numeric(inventoryStatus)
############################
## Pull Commerce/Price Data
############################
priceInfo <- vector("numeric", length(inventoryStatus))
prices<- vector("numeric", length(inventoryStatus))
answer_json<- vector("numeric", length(inventoryStatus))
for(i in 1:length(inventoryStatus)) {
eventID <- inventoryStatus[i]
commerceLink <- function(apiKey, eventID){
rootURL<-"https://app.ticketmaster.com/commerce/v2/events"
params<-c("/", "/offers.json?apikey=")
values<- c(eventID, apiKey)
args<- str_c(params, values, collapse = "")
str_c(rootURL, args)
}
priceInfo[i]<-commerceLink(apiKey,eventID)
con<-curl(priceInfo[i])
answer_json[i]<-readLines(con)
}
prices[i]<-
answer_json[i] %>%
prettify() %>%
fromJSON()
########################################
## Combine Dataframes and Export to CSV
########################################
#write.csv(x=data,file="nflData_2018-08-16_1.csv")
inventoryStatus<-str_replace(answer_json, "{[[:punct:]]}", "")
#install.packages(c("tidyverse", "stringr", "knitr", "curl", "jsonlite", "XML", "httr", "rvest", "ggmap"))
library(tidyverse)
library(stringr)
library(knitr)
library(curl)
library(jsonlite)
library(XML)
library(httr)
library(rvest)
library(ggmap)
###################
## Pull Event Data
###################
apiKey<-"BDMDMNv2wXwAZMRAlavHs371eUadxLbq"
consumerSecret<-"o8eJaby9afZL45s3"
keyword<-"NFL"
segmentID<-"KZFzniwnSyZfZ7v7nE"
sementName<-"Sports"
genreID<-"KnvZfZ7vAdE"
genreName<-"Football"
subgenreID<-"KZazBEonSMnZfZ7vFE1"
subgenreName<-"NFL"
typeID<-"KZAyXgnZfZ7v7l1"
typeName<-"Group"
subtypeID<-"KZFzBErXgnZfZ7vA7d"
subtypeName<-"Team"
size<-200
# Function for API Query
ticketMasterLink <- function(apiKey, keyword, size){
rootURL<-"https://app.ticketmaster.com/discovery/v2/events.json?"
params<-c( "apikey=", "keyword=","size=")
values<- c(apiKey, keyword, size)
args<- str_c(params, values, collapse = "&")
str_c(rootURL, args)
}
# requestNFLGames
nflGames<-ticketMasterLink(apiKey,keyword,size)
con<-curl(nflGames)
answer_json<-readLines(con)
response<-
answer_json %>%
prettify() %>%
fromJSON()
eventData<-response$`_embedded`$events
eventData<-eventData[!(eventData$dates$status$code %in% c("offsale")), ]
eventData<-eventData[(eventData$promoter$id %in% c("705")), ]
#############################
## Pull Inventory Status Data
#############################
inventoryInfo <- vector("numeric", nrow(eventData))
inventory<- vector("numeric", nrow(eventData))
answer_json<- vector("numeric", nrow(eventData))
for (i in 1:nrow(eventData)) {
inventoryStatusLink <- function(apiKey, eventID){
eventID <- eventData[i,3]
rootURL<-"https://app.ticketmaster.com/inventory-status/v1/availability?"
params<-c("events=", "apikey=")
values<- c(eventID, apiKey)
args<- str_c(params, values, collapse = "&")
str_c(rootURL, args)
}
inventoryInfo[i]<-inventoryStatusLink(apiKey,eventID)
con<-curl(inventoryInfo[i])
answer_json[i]<-readLines(con)
inventory[i]<-
answer_json[i] %>%
prettify() %>%
fromJSON()
}
x <- "{}" #or whatever
inventoryStatus<-str_replace(answer_json, "{[[:punct:]]}", "")
inventoryStatus<-str_replace_all(inventoryStatus, "eventId","")
inventoryStatus<-str_replace_all(inventoryStatus, "status","")
inventoryStatus<-str_replace_all(inventoryStatus,"FEWTICKETSLEFT", "")
inventoryStatus<-str_replace_all(inventoryStatus,"TICKETSAVAILABLE", "")
inventoryStatus<-inventoryStatus[!grepl("TICKETSNOTAVAILABLE", inventoryStatus)]
#inventoryStatus<-as.numeric(inventoryStatus)
############################
## Pull Commerce/Price Data
############################
priceInfo <- vector("numeric", length(inventoryStatus))
prices<- vector("numeric", length(inventoryStatus))
answer_json<- vector("numeric", length(inventoryStatus))
for(i in 1:length(inventoryStatus)) {
eventID <- inventoryStatus[i]
commerceLink <- function(apiKey, eventID){
rootURL<-"https://app.ticketmaster.com/commerce/v2/events"
params<-c("/", "/offers.json?apikey=")
values<- c(eventID, apiKey)
args<- str_c(params, values, collapse = "")
str_c(rootURL, args)
}
priceInfo[i]<-commerceLink(apiKey,eventID)
con<-curl(priceInfo[i])
answer_json[i]<-readLines(con)
}
prices[i]<-
answer_json[i] %>%
prettify() %>%
fromJSON()
########################################
## Combine Dataframes and Export to CSV
########################################
#write.csv(x=data,file="nflData_2018-08-16_1.csv")
inventoryStatus<-str_replace_all(answer_json, "{}", "")
inventoryStatus<-str_replace_all(answer_json, "{}", " ")
x <- "{}" #or whatever
inventoryStatus<-str_replace_all(answer_json, x, " ")
?? box plot
??boxplot
??box
install.packages("read_xl")
install.packages("readxl")
library(readxl)
data<-read_xlsx(file="angry_moods.xlsx", HEADER = TRUE)
data<-read_xlsx("angry_moods.xlsx", HEADER = TRUE)
setwd()
dir()
?binomial
?gbinom
??gbinom
?dbinom
dbinom(5:10, 60, 0.667)
x<-dbinom(5:10, 60, 0.667)
sum(x)
x<-dbinom(5:10, 60, 1/3)
x
sum(x)
sum(dbinom(15:60,60,1/3))
1-sum(dbinom(0:14,60,1/3))
sum(dbinom(40:60,60,1/3))
1-sum(dbinom(0:40,60,1/3)
)
1-sum(dbinom(0:39,60,1/3)
)
60*(1/3)
1/3
dbinom(20,60,1/3)
dbinom(19,60,1/3)
dbinom(25,60,1/3)
dbinom(21,60,1/3)
dbinom(5,60,1/3)
dbinom(8,60,1/3)
dbinom(30,60,1/3)
sum(dbinom(0:25,50,0.65)
)
?dnorm
sum(dbinom(15:18,25,0.5))
install.packages("readxl")
library(readxl)
data<-read_xlsx("angry_moods.xlsx")
data<-read_xlsx(file="angry_moods.xlsx")
data<-read_xlsx(angry_moods.xlsx")
data<-read_xlsx("angry_moods.xlsx")
dir()
dir()
??confidenceinterval
?confidence
?confint
?norm
setwd('C:/Users/g1mxb12/Desktop/nflTicketPrices/data/seatgeek')
data = load('sg_2018-12-11.RData')
View(eventData)
View(eventData)
